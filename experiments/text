1.Заглавна страница
Тема: Система за видео наблюдение през уеб (Live Streaming)
Автор: Костадин Пидов
Дата, учебна дисциплина, преподавател

2.Увод
Кратко въведение в целите и значението на уеб видео наблюдението
Кратко описание на съдържанието: теоретична и практическа части
Теоретична част — HTTP Streaming

3.1. Въведение в стрийминг медиите
Разлика между прогресивно зареждане (progressive download) и стрийминг
Основни концепции: latency, bandwidth, buffer, codec, container

3.2. Протоколи и технологии за стрийминг
HTTP базирани протоколи: HLS (HTTP Live Streaming), MPEG-DASH, Progressive HTTP, MJPEG over HTTP
Сравнение: HLS vs MPEG-DASH vs WebRTC vs RTSP/RTMP (защо някои са над HTTP и кога се използват)

3.3. HTTP Streaming: принцип и архитектура
Как работи HTTP streaming (секвениране на сегменти, manifest/playlist за HLS и MPD за DASH)
Формати на сегментите (TS, fMP4)
Chunked Transfer Encoding и Server-Sent Events (кратко)
MJPEG over HTTP — директно подаване на последователни JPEG кадри в един HTTP отговор (подходящ за простичък live view)

3.4. Кодеци и компресия
Популярни кодеци: H.264, H.265, VP8/9, AV1
Влияние на битрейт и резолюция върху латентност и качество

3.5. Кеширане и CDN
Ролята на CDN за мащабируемост
Как HTTP базираният стрийминг използва кеширане (предизвикателства при live content)

3.6. Сигурност и автентикация
HTTPS, token-based access, signed URLs, CORS настройки

3.7. Заключение на теоретичната част
Кога да се използва HTTP streaming и какви са trade-off
Практическа част — изисквания и дизайн

4.1. Цел и функционални изисквания
Свързване към IP видео камера (RTSP/HTTP поток или USB камера)
Показване на видео „на живо“ в уеб интерфейс (в браузър)
Реализиране на детекция на движение чрез разлика между два последователни кадъра
Запис и/или snapshot при засечено движение (опционално)
Настройки: чувствителност, зона на интерес (ROI), честота на проверка
Интерфейс: бутон Start/Stop, показване на статус, лог на събития

4.2. Нефункционални изисквания
Реален/нисколатентен стрийм (желана латентност, напр. <1–2 s за MJPEG/WebRTC, <5–10 s за HLS)
Поддържани резолюции и кадрови честоти
Портируемост (работа в модерни браузъри), минимални хардуерни изисквания

4.3. Архитектура на системата
Компоненти: Камера → Streaming server/Proxy (ако е нужно) → Backend (optional) → Frontend (в браузъра)
Възможни подходи: MJPEG over HTTP (лесен), HLS/DASH (буферирано), WebRTC (ниска латентност)
Блок диаграма (описателно)

4.4. Избор на технологии и инструменти (примерни предложения)
Камера: IP камера с RTSP изход или USB камера (V4L2)
Backend: Python (Flask/FastAPI), Node.js (Express), Go (net/http)
Видео обработка и детекция: OpenCV (Python или C++), FFmpeg за трансформиране на потока
Frontend: HTML5, JavaScript; за MJPEG — <img src="...">; за HLS — hls.js; за WebRTC — RTCPeerConnection API
Библиотеки: opencv-python, aiortc (за WebRTC), ffmpeg
Реализация — стъпка по стъпка (примерен workflow, Python + OpenCV + Flask, MJPEG)

5.1. Среда и предварителни стъпки
Инсталация на зависимости: Python 3.x, pip install opencv-python flask imutils (пример)
Настройка на камерата (RTSP URL или device index)
5.2. Захващане на видео (capture)

Код за отваряне на видео поток (cv2.VideoCapture(rtsp_url или device))
Настройки: resize, fps control
5.3. Генериране на MJPEG поток от кадри
Функция/генератор, която чете кадри, кодира в JPEG и yield-ва multipart/x-mixed-replace отговор
Примерен HTTP endpoint в Flask: /video_feed, Content-Type: multipart/x-mixed-replace; boundary=frame

5.4. Детекция на движение (difference between frames)
Настройки: минимална площ за детекция (min_area), threshold, blur параметри
Маркиране с рамки (bounding boxes) и логване на събитията
Опционално: debounce/супресия, за да не се записва многократно едно събитие

5.5. Интеграция на детекцията в MJPEG потока
Вкарване на маркираните кадри в потока, добавяне на overlay текст със статус и timestamp
При засичане на движение: изпращане на уведомление (console, запис в база/файл, email или webhook — опционално) и съхранение на кадър/клип

5.6. Frontend
Проста HTML страница с <img src="/video_feed"> или video елемент за HLS/WebRTC
Контроли: Start/Stop, slider за чувствителност, чекбокс за записи, панел със събития

5.7. Тестове и валидация
Тестване при различни осветления, шум, движение на листа/камера
Метрики: false positives/negatives, CPU/RAM натоварване, latency (реално измерване)

6.Код — пример (структура)
Примерни именувания на файлове: app.py, camera.py, motion_detector.py, templates/index.html, static/js/main.js
Кратък коментар към основните функции (capture, generate_mjpeg, detect_motion)

7.Разширения и подобрения (предложения)
Използване на WebRTC за много по-ниска латентност (aiortc, mediasoup)
Замяна на простата детекция с background subtraction (MOG2) или ML-базирани модели (YOLO/SSD) за детекция на хора/обекти
Записване на видео сегменти, управление на архив, компресиране, ротация на логове
Мащабиране с RTMP/NGINX+rtmp/module или медийни сървъри (Janus, Kurento)

8.Сигурност и етика
Поверителност, GDPR (ако се събира лични данни)
Сигурни връзки (HTTPS), автентикация за достъп до видео, логове на достъп

9.Заключение
Обобщение на реализирания минимум и възможности за развитие

10.Приложения (Appendix)
Пълен примерен код (или линк към репозиториум)
Списък с ресурси и литература (документация HLS, OpenCV, FFmpeg, WebRTC)
Команди за инсталация и стартиране